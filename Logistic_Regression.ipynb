{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66442e17",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d16de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a6a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/darshmac/Documents/cdac/For DBDA/PML/Cases/human-resources-analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc23591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Department</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6</td>\n",
       "      <td>247</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>224</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14995 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.10             0.77               6   \n",
       "3                    0.92             0.85               5   \n",
       "4                    0.89             1.00               5   \n",
       "...                   ...              ...             ...   \n",
       "14990                0.40             0.57               2   \n",
       "14991                0.37             0.48               2   \n",
       "14992                0.37             0.53               2   \n",
       "14993                0.11             0.96               6   \n",
       "14994                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                       157                   3              0     1   \n",
       "1                       262                   6              0     1   \n",
       "2                       247                   4              0     1   \n",
       "3                       259                   5              0     1   \n",
       "4                       224                   5              0     1   \n",
       "...                     ...                 ...            ...   ...   \n",
       "14990                   151                   3              0     1   \n",
       "14991                   160                   3              0     1   \n",
       "14992                   143                   3              0     1   \n",
       "14993                   280                   4              0     1   \n",
       "14994                   158                   3              0     1   \n",
       "\n",
       "       promotion_last_5years Department  salary  \n",
       "0                          0      sales     low  \n",
       "1                          0      sales  medium  \n",
       "2                          0      sales     low  \n",
       "3                          0      sales     low  \n",
       "4                          0      sales     low  \n",
       "...                      ...        ...     ...  \n",
       "14990                      0    support     low  \n",
       "14991                      0    support     low  \n",
       "14992                      0    support     low  \n",
       "14993                      0    support     low  \n",
       "14994                      0    support     low  \n",
       "\n",
       "[14995 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = pd.read_csv(\"HR_comma_sep.csv\")\n",
    "hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6f849d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11428\n",
      "1     3567\n",
      "Name: left, dtype: int64\n",
      "0    76.212071\n",
      "1    23.787929\n",
      "Name: left, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dum_hr = pd.get_dummies(hr,drop_first=True)\n",
    "print(hr['left'].value_counts())\n",
    "print(hr['left'].value_counts(normalize=True)*100)# kitne percent me 0 and 1 hain\n",
    "#means kitne logo ne company left ki and kitne hai %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2084c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dum_hr,test_size=0.3,\n",
    "                              stratify=hr['left'],\n",
    "                              random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de90f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('left', axis=1)\n",
    "y_test = test['left']\n",
    "X_train = train.drop('left',axis=1)\n",
    "y_train = train['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c381066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    76.209985\n",
      "1    23.790015\n",
      "Name: left, dtype: float64\n",
      "0    76.216937\n",
      "1    23.783063\n",
      "Name: left, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(normalize=True)*100)#kitne percent me 0 and 1 hai \n",
    "print(y_test.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6945aedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "086b99ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.04001088e+00  1.24582625e-01 -2.64097022e-01  3.51951025e-03\n",
      "   2.34609716e-01 -1.67685498e+00 -6.75394088e-01 -4.24532141e-01\n",
      "   1.39970076e-01  3.68105472e-01 -4.99960340e-01 -8.02944545e-02\n",
      "  -1.64241046e-01  5.94810107e-03  2.66039727e-01  3.37013988e-01\n",
      "   1.40384066e+00  8.03172658e-01]]\n",
      "[-0.52703339]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e39807",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "y_pred_prob = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "645b0a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[[0.7953282  0.2046718 ]\n",
      " [0.66090907 0.33909093]\n",
      " [0.7945521  0.2054479 ]\n",
      " ...\n",
      " [0.98019233 0.01980767]\n",
      " [0.54918518 0.45081482]\n",
      " [0.9086005  0.0913995 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90e8c4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8039564347632807\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015e00e",
   "metadata": {},
   "source": [
    "**GridSearch**\n",
    "StratifiedKFold introduced (performs good for categorical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc3f64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "925d3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dum_hr.drop('left', axis=1)\n",
    "y = dum_hr['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "147cb782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Department_RandD</th>\n",
       "      <th>Department_accounting</th>\n",
       "      <th>Department_hr</th>\n",
       "      <th>Department_management</th>\n",
       "      <th>Department_marketing</th>\n",
       "      <th>Department_product_mng</th>\n",
       "      <th>Department_sales</th>\n",
       "      <th>Department_support</th>\n",
       "      <th>Department_technical</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6</td>\n",
       "      <td>247</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>224</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14995 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.10             0.77               6   \n",
       "3                    0.92             0.85               5   \n",
       "4                    0.89             1.00               5   \n",
       "...                   ...              ...             ...   \n",
       "14990                0.40             0.57               2   \n",
       "14991                0.37             0.48               2   \n",
       "14992                0.37             0.53               2   \n",
       "14993                0.11             0.96               6   \n",
       "14994                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  \\\n",
       "0                       157                   3              0   \n",
       "1                       262                   6              0   \n",
       "2                       247                   4              0   \n",
       "3                       259                   5              0   \n",
       "4                       224                   5              0   \n",
       "...                     ...                 ...            ...   \n",
       "14990                   151                   3              0   \n",
       "14991                   160                   3              0   \n",
       "14992                   143                   3              0   \n",
       "14993                   280                   4              0   \n",
       "14994                   158                   3              0   \n",
       "\n",
       "       promotion_last_5years  Department_RandD  Department_accounting  \\\n",
       "0                          0                 0                      0   \n",
       "1                          0                 0                      0   \n",
       "2                          0                 0                      0   \n",
       "3                          0                 0                      0   \n",
       "4                          0                 0                      0   \n",
       "...                      ...               ...                    ...   \n",
       "14990                      0                 0                      0   \n",
       "14991                      0                 0                      0   \n",
       "14992                      0                 0                      0   \n",
       "14993                      0                 0                      0   \n",
       "14994                      0                 0                      0   \n",
       "\n",
       "       Department_hr  Department_management  Department_marketing  \\\n",
       "0                  0                      0                     0   \n",
       "1                  0                      0                     0   \n",
       "2                  0                      0                     0   \n",
       "3                  0                      0                     0   \n",
       "4                  0                      0                     0   \n",
       "...              ...                    ...                   ...   \n",
       "14990              0                      0                     0   \n",
       "14991              0                      0                     0   \n",
       "14992              0                      0                     0   \n",
       "14993              0                      0                     0   \n",
       "14994              0                      0                     0   \n",
       "\n",
       "       Department_product_mng  Department_sales  Department_support  \\\n",
       "0                           0                 1                   0   \n",
       "1                           0                 1                   0   \n",
       "2                           0                 1                   0   \n",
       "3                           0                 1                   0   \n",
       "4                           0                 1                   0   \n",
       "...                       ...               ...                 ...   \n",
       "14990                       0                 0                   1   \n",
       "14991                       0                 0                   1   \n",
       "14992                       0                 0                   1   \n",
       "14993                       0                 0                   1   \n",
       "14994                       0                 0                   1   \n",
       "\n",
       "       Department_technical  salary_low  salary_medium  \n",
       "0                         0           1              0  \n",
       "1                         0           0              1  \n",
       "2                         0           1              0  \n",
       "3                         0           1              0  \n",
       "4                         0           1              0  \n",
       "...                     ...         ...            ...  \n",
       "14990                     0           1              0  \n",
       "14991                     0           1              0  \n",
       "14992                     0           1              0  \n",
       "14993                     0           1              0  \n",
       "14994                     0           1              0  \n",
       "\n",
       "[14995 rows x 18 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11bf138d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11428\n",
       "1     3567\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98498284",
   "metadata": {},
   "source": [
    "solver{‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}, default=’lbfgs’<br>\n",
    "Algorithm to use in the optimization problem. Default is ‘lbfgs’. To choose a solver, you might want to consider the following aspects:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a345fdc",
   "metadata": {},
   "source": [
    "The Elastic-Net regularization is only supported by the ‘saga’ solver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231263e",
   "metadata": {},
   "source": [
    "Warning The choice of the algorithm depends on the penalty chosen. Supported penalties by solver:\n",
    "‘lbfgs’ - [‘l2’, None]\n",
    "\n",
    "‘liblinear’ - [‘l1’, ‘l2’]\n",
    "\n",
    "‘newton-cg’ - [‘l2’, None]\n",
    "\n",
    "‘newton-cholesky’ - [‘l2’, None]\n",
    "\n",
    "‘sag’ - [‘l2’, None]\n",
    "\n",
    "‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca113966",
   "metadata": {},
   "outputs": [],
   "source": [
    "lor = LogisticRegression(solver = 'saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90361f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "400aa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "          'l1_ratio': np.linspace(0, 1, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68dd0078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1171: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/Users/darshmac/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(solver=&#x27;saga&#x27;),\n",
       "             param_grid={&#x27;l1_ratio&#x27;: array([0.  , 0.25, 0.5 , 0.75, 1.  ]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(solver=&#x27;saga&#x27;),\n",
       "             param_grid={&#x27;l1_ratio&#x27;: array([0.  , 0.25, 0.5 , 0.75, 1.  ]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=23, shuffle=True),\n",
       "             estimator=LogisticRegression(solver='saga'),\n",
       "             param_grid={'l1_ratio': array([0.  , 0.25, 0.5 , 0.75, 1.  ]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None]})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv = GridSearchCV(lor,param_grid=params,cv=kfold)\n",
    "gcv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "384614a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.0, 'penalty': 'l1'}\n",
      "0.7571190396798932\n"
     ]
    }
   ],
   "source": [
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10fa0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_cv = pd.DataFrame(gcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "261b0042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.503121</td>\n",
       "      <td>0.028654</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'l1_ratio': 0.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.757119</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.370917</td>\n",
       "      <td>0.026125</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'l1_ratio': 0.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756586</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.368864</td>\n",
       "      <td>0.021533</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'l1_ratio': 0.0, 'penalty': 'elasticnet'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.329573</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'l1_ratio': 0.0, 'penalty': None}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756586</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.455453</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.25</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'l1_ratio': 0.25, 'penalty': 'l1'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.340187</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.25</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'l1_ratio': 0.25, 'penalty': 'l2'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.474210</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.25</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'l1_ratio': 0.25, 'penalty': 'elasticnet'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756586</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.330921</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "      <td>{'l1_ratio': 0.25, 'penalty': None}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756586</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.454995</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'l1_ratio': 0.5, 'penalty': 'l1'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.333592</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'l1_ratio': 0.5, 'penalty': 'l2'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756586</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.461519</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.5</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'l1_ratio': 0.5, 'penalty': 'elasticnet'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.347825</td>\n",
       "      <td>0.022377</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'l1_ratio': 0.5, 'penalty': None}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756586</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.455691</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.75</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'l1_ratio': 0.75, 'penalty': 'l1'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.756252</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757119</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.347117</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.75</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'l1_ratio': 0.75, 'penalty': 'l2'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.756252</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756586</td>\n",
       "      <td>0.756986</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.457837</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.75</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'l1_ratio': 0.75, 'penalty': 'elasticnet'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.334939</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.75</td>\n",
       "      <td>None</td>\n",
       "      <td>{'l1_ratio': 0.75, 'penalty': None}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.455081</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'l1_ratio': 1.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.756252</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757119</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.344904</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'l1_ratio': 1.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.756986</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.454874</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'l1_ratio': 1.0, 'penalty': 'elasticnet'}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.759253</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.329299</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'l1_ratio': 1.0, 'penalty': None}</td>\n",
       "      <td>0.755919</td>\n",
       "      <td>0.756252</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.756919</td>\n",
       "      <td>0.757052</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.503121      0.028654         0.003815        0.000415   \n",
       "1        0.370917      0.026125         0.003389        0.000183   \n",
       "2        0.368864      0.021533         0.003792        0.000436   \n",
       "3        0.329573      0.003634         0.003446        0.000196   \n",
       "4        0.455453      0.004523         0.003530        0.000134   \n",
       "5        0.340187      0.006099         0.003334        0.000082   \n",
       "6        0.474210      0.008904         0.003422        0.000211   \n",
       "7        0.330921      0.004647         0.003368        0.000133   \n",
       "8        0.454995      0.008746         0.003300        0.000145   \n",
       "9        0.333592      0.009447         0.003453        0.000285   \n",
       "10       0.461519      0.007162         0.003432        0.000226   \n",
       "11       0.347825      0.022377         0.003353        0.000132   \n",
       "12       0.455691      0.007930         0.003388        0.000270   \n",
       "13       0.347117      0.006340         0.003267        0.000158   \n",
       "14       0.457837      0.008710         0.003398        0.000170   \n",
       "15       0.334939      0.007542         0.003347        0.000168   \n",
       "16       0.455081      0.007722         0.003280        0.000161   \n",
       "17       0.344904      0.004471         0.003423        0.000157   \n",
       "18       0.454874      0.005698         0.003277        0.000157   \n",
       "19       0.329299      0.004175         0.003443        0.000215   \n",
       "\n",
       "   param_l1_ratio param_penalty                                       params  \\\n",
       "0             0.0            l1           {'l1_ratio': 0.0, 'penalty': 'l1'}   \n",
       "1             0.0            l2           {'l1_ratio': 0.0, 'penalty': 'l2'}   \n",
       "2             0.0    elasticnet   {'l1_ratio': 0.0, 'penalty': 'elasticnet'}   \n",
       "3             0.0          None           {'l1_ratio': 0.0, 'penalty': None}   \n",
       "4            0.25            l1          {'l1_ratio': 0.25, 'penalty': 'l1'}   \n",
       "5            0.25            l2          {'l1_ratio': 0.25, 'penalty': 'l2'}   \n",
       "6            0.25    elasticnet  {'l1_ratio': 0.25, 'penalty': 'elasticnet'}   \n",
       "7            0.25          None          {'l1_ratio': 0.25, 'penalty': None}   \n",
       "8             0.5            l1           {'l1_ratio': 0.5, 'penalty': 'l1'}   \n",
       "9             0.5            l2           {'l1_ratio': 0.5, 'penalty': 'l2'}   \n",
       "10            0.5    elasticnet   {'l1_ratio': 0.5, 'penalty': 'elasticnet'}   \n",
       "11            0.5          None           {'l1_ratio': 0.5, 'penalty': None}   \n",
       "12           0.75            l1          {'l1_ratio': 0.75, 'penalty': 'l1'}   \n",
       "13           0.75            l2          {'l1_ratio': 0.75, 'penalty': 'l2'}   \n",
       "14           0.75    elasticnet  {'l1_ratio': 0.75, 'penalty': 'elasticnet'}   \n",
       "15           0.75          None          {'l1_ratio': 0.75, 'penalty': None}   \n",
       "16            1.0            l1           {'l1_ratio': 1.0, 'penalty': 'l1'}   \n",
       "17            1.0            l2           {'l1_ratio': 1.0, 'penalty': 'l2'}   \n",
       "18            1.0    elasticnet   {'l1_ratio': 1.0, 'penalty': 'elasticnet'}   \n",
       "19            1.0          None           {'l1_ratio': 1.0, 'penalty': None}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.755919           0.755919           0.757252   \n",
       "1            0.755919           0.755919           0.757252   \n",
       "2            0.755919           0.755919           0.757252   \n",
       "3            0.755919           0.755919           0.757252   \n",
       "4            0.755919           0.755919           0.757252   \n",
       "5            0.755919           0.755919           0.757252   \n",
       "6            0.755919           0.755919           0.757252   \n",
       "7            0.755919           0.755919           0.757252   \n",
       "8            0.755919           0.755919           0.757252   \n",
       "9            0.755919           0.755919           0.757252   \n",
       "10           0.755919           0.755919           0.757252   \n",
       "11           0.755919           0.755919           0.757252   \n",
       "12           0.755919           0.756252           0.757252   \n",
       "13           0.755919           0.756252           0.757252   \n",
       "14           0.755919           0.755919           0.757252   \n",
       "15           0.755919           0.755919           0.757252   \n",
       "16           0.755919           0.756252           0.757252   \n",
       "17           0.755919           0.755919           0.757252   \n",
       "18           0.755919           0.755919           0.757252   \n",
       "19           0.755919           0.756252           0.757252   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.759253           0.757252         0.757119        0.001222   \n",
       "1            0.758920           0.756586         0.756919        0.001116   \n",
       "2            0.759253           0.756919         0.757052        0.001222   \n",
       "3            0.758920           0.756586         0.756919        0.001116   \n",
       "4            0.759253           0.756919         0.757052        0.001222   \n",
       "5            0.759253           0.756919         0.757052        0.001222   \n",
       "6            0.758920           0.756586         0.756919        0.001116   \n",
       "7            0.758920           0.756586         0.756919        0.001116   \n",
       "8            0.759253           0.756919         0.757052        0.001222   \n",
       "9            0.758920           0.756586         0.756919        0.001116   \n",
       "10           0.759253           0.756919         0.757052        0.001222   \n",
       "11           0.758920           0.756586         0.756919        0.001116   \n",
       "12           0.759253           0.756919         0.757119        0.001167   \n",
       "13           0.758920           0.756586         0.756986        0.001063   \n",
       "14           0.759253           0.756919         0.757052        0.001222   \n",
       "15           0.759253           0.756919         0.757052        0.001222   \n",
       "16           0.759253           0.756919         0.757119        0.001167   \n",
       "17           0.758920           0.756919         0.756986        0.001104   \n",
       "18           0.759253           0.756919         0.757052        0.001222   \n",
       "19           0.758920           0.756919         0.757052        0.001046   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                15  \n",
       "2                 4  \n",
       "3                15  \n",
       "4                 4  \n",
       "5                 4  \n",
       "6                15  \n",
       "7                15  \n",
       "8                 4  \n",
       "9                15  \n",
       "10                4  \n",
       "11               15  \n",
       "12                1  \n",
       "13               13  \n",
       "14                4  \n",
       "15                4  \n",
       "16                1  \n",
       "17               13  \n",
       "18                4  \n",
       "19                4  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_cv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
